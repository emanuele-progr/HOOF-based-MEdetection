ISTRUZIONI PER ESEGUIRE CORRETTAMENTE IL PROGRAMMA E RIPRODURRE I RISULTATI

-Per ottenere la matrice di confusione presente nei risultati vanno
 scaricati tutti i file presenti nella cartella source e mantenuto
 l'ordinamento.
 Sono già presenti i dataset necessari, i modelli addestrati e i 
 file con i dati da testare dove il test set è formato da descrittori
 estratti dai soggetti 9-17-18-21 del dataset CASME2 e i dataset per
 il training sono costituiti da alcuni descrittori di tutti i rimanenti
 soggetti del dataset.
 La funzione fast_SVMpredict() si occuperà di usare i modelli per 
 ottenere predizioni sul testset (le cui true label sono state inserite
 in un vettore) e costruirà la matrice di confusione calcolando alcuni
 parametri di confronto.
 Per riprodurre dunque i risultati deve essere semplicemente eseguito 
 il file results.py.

-Per fare predizioni su sequenze video di CASME2, una volta eseguito il
 file main.py, deve essere inserito il path al soggetto da testare come richiesto
 dalla print sul terminale.
 Per la fase di preprocessing, va scaricato il file
 'shape_predictor_68_face_landmarks.dat' per l'individuazione dei 
 landmarks (https://github.com/AKSHAYUBHAT/TensorFace/blob/master/open
 face/models/dlib/shape_predictor_68_face_landmarks.dat) e collocato
 nella cartella source.
 Il programma scorrerà frame by frame e farà via via predizioni
 in base ai modelli presenti nella cartella source.
 Inoltre verranno generati file .txt contenenti i descrittori relativi
 ai 3 ROI in formato libSVM ma divisi da caratteri in base alle finestre
 e alle cartelle.
 Questi sono file che contengono i descrittori divisi da una riga "AAA" per
 indicare la separazione tra due finestre e la riga "END" per indicare la
 fine del subfolder.
 Questi file "raw" relativi alle diverse ROIs( datax0 -> lips/mouth
 datax1 -> left eyebrow  datax2 -> right eyebrow )
 devono poi essere etichettati a mano data la complessità
 del task seguendo la tabella excel "CASME2-coding" , la tabella degli AUs
 reperibile online (https://en.wikipedia.org/wiki/Facial_Action_Coding_System)
 e impostando una soglia di true positive.
 ESEMPIO: microespressione con AU 10 (dalla tabella --> "upper lip raiser")
 nei frame 50 - 150. Con una soglia 80% questa deve essere effettivamente 
 segnalata come true positive +1, per il training del modello relativo
 alla bocca, nella seconda finestra ( che và da 60 a 160) e come esempio
 negativo +2 nella prima finestra.
 Quindi devono essere eliminati i caratteri "AAA" e "END" e messe a "+1"
 invece che a "+2" (valore di default) le finestre relative a una ME.
 Bisogna in sostanza ottenere un file .txt simile in formato ai dataset
 allegati col codice; per verificare la correttezza formale del file si può 
 usare tramite terminale lo script "checkdata.py" dei tools di libSVM.
 A questo punto devono essere costruiti 3 dataset, uno per ROI, bilanciando
 gli esempi +1 e +2 e, per addestrare modelli diversi, è presente la 
 funzione SVM_model in svm.py che, dato in ingresso un opportuno dataset,
 rende in uscita il relativo modello.
 Questo può poi essere utilizzato inserendo il nome del file modello nella
 funzione "SVM_predict" e il range file relativo al dataset di addestramento
 che è stato generato nello step precedente.
 A questo punto il programma userà il modello inserito per le predizioni
 frame by frame.

     
Per maggiori dettagli, consultare la relazione.
